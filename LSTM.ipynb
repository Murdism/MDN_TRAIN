{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt # creating visualizations\n",
    "import numpy as np # basic math and random numbers\n",
    "import torch # package for building functions with learnable parameters\n",
    "import torch.nn as nn # prebuilt functions specific to neural networks\n",
    "from torch.autograd import Variable # storing data while learning\n",
    "#from disp import ADE,FDE,prediction_displacement,ADE_double_coordinates,FDE_double_coordinates,prediction_displacement_double\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Predict error\n",
    "# Average Displacement error\n",
    "\n",
    "def ADE(pred,truth): \n",
    "    counter=0\n",
    "    sum=0\n",
    "    for i in range(len(pred)):\n",
    "        half=int(len(pred[i])/2)\n",
    "        for j in range (half):\n",
    "\n",
    "            a = np.array((pred[i][j] , pred[i][half+j]))\n",
    "            b = np.array((truth.iloc[i][j] , truth.iloc[i][half+j]))\n",
    "\n",
    "            dist = np.linalg.norm(a-b)\n",
    "            sum+=dist\n",
    "            counter+=1\n",
    "            #print(\"Distance between\",a,\" and \",b,\" is: \",dist)\n",
    "\n",
    "    return (sum/counter)\n",
    "def prediction_displacement_double(pred): \n",
    "          \n",
    "        sum=0\n",
    "        counter=0        \n",
    "        pred=np.array(pred)\n",
    "        last_index= (len(pred[0])-1)\n",
    "        \n",
    "        for i in range(len(pred)):\n",
    "                \n",
    "                    a = np.array((pred[i][0][0] , pred[i][0][1]))\n",
    "                    b = np.array((pred[i][last_index][0] , pred[i][last_index][1]))\n",
    "\n",
    "                    dist = np.linalg.norm(a-b)\n",
    "                    sum+=dist\n",
    "                    counter+=1\n",
    "        return (sum/counter)\n",
    "\n",
    "def prediction_displacement(pred): \n",
    "    counter=0\n",
    "    sum=0\n",
    "    pred=np.array(pred)\n",
    "    for i in range(len(pred)):\n",
    "        half=int(len(pred[i])/2)\n",
    "        last=(len(pred[i]) - 1)\n",
    "\n",
    "        a = np.array((pred[i][0] , pred[i][half]))\n",
    "        b = np.array((pred[i][half-1] , pred[i][last]))\n",
    "\n",
    "        dist = np.linalg.norm(a-b)\n",
    "        sum+=dist\n",
    "        counter+=1\n",
    "        #print(\"FDE Distance between\",a,\" and \",b,\" is: \",dist)\n",
    "            \n",
    "    return (sum/counter)\n",
    "def FDE(pred,truth): \n",
    "    counter=0\n",
    "    sum=0\n",
    "    for i in range(len(pred)):\n",
    "        half=int(len(pred[i])/2)\n",
    "        last=(len(pred[i]) - 1)\n",
    "\n",
    "        a = np.array((pred[i][half-1] , pred[i][last]))\n",
    "        b = np.array((truth.iloc[i][half-1] , truth.iloc[i][last]))\n",
    "\n",
    "        dist = np.linalg.norm(a-b)\n",
    "        sum+=dist\n",
    "        counter+=1\n",
    "        #print(\"FDE Distance between\",a,\" and \",b,\" is: \",dist)\n",
    "            \n",
    "    return (sum/counter)\n",
    "\n",
    "\n",
    "def FDE_double_coordinates(pred,truth):\n",
    "          \n",
    "        sum=0\n",
    "        counter=0\n",
    "        \n",
    "        pred=np.array(pred)\n",
    "        truth=np.array(truth)\n",
    "        last_index= (len(pred[0])-1)\n",
    "\n",
    "        for i in range(len(pred)):\n",
    "                \n",
    "            a = np.array((pred[i][last_index][0] , pred[i][last_index][1]))\n",
    "            b = np.array((truth[i][last_index][0] , truth[i][last_index][1]))\n",
    "\n",
    "            dist = np.linalg.norm(a-b)\n",
    "            sum+=dist\n",
    "            counter+=1\n",
    "\n",
    "                # for j in range (len(pred[i])):\n",
    "                #    pred_x.append(pred[i][j][0])  \n",
    "                #    pred_y.append(pred[i][j][1]) \n",
    "\n",
    "                #    truth_x.append(truth[i][j][0])  \n",
    "                #    truth_y.append(truth[i][j][1])\n",
    "        return (sum/counter)\n",
    "def ADE_double_coordinates(pred,truth):\n",
    "          \n",
    "        sum=0\n",
    "        counter=0\n",
    "        \n",
    "        pred=np.array(pred)\n",
    "        truth=np.array(truth)\n",
    "\n",
    "        for i in range(len(pred)):\n",
    "                \n",
    "                for j in range (len(pred[i])):\n",
    "\n",
    "                    a = np.array((pred[i][j][0] , pred[i][j][1]))\n",
    "                    b = np.array((truth[i][j][0] , truth[i][j][1]))\n",
    "\n",
    "                    dist = np.linalg.norm(a-b)\n",
    "                    sum+=dist\n",
    "                    counter+=1\n",
    "        return (sum/counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('train_input.pickle', 'rb') as data:\n",
    "     train_input = pickle.load(data)\n",
    "    with open('validate_input.pickle', 'rb') as data:\n",
    "         validate_input= pickle.load(data)\n",
    "    with open('test_input.pickle', 'rb') as data:\n",
    "         test_input = pickle.load(data)\n",
    "    with open('train_target.pickle', 'rb') as data:\n",
    "          train_target = pickle.load(data)\n",
    "    with open('validate_target.pickle', 'rb') as data:\n",
    "          validate_target = pickle.load(data)\n",
    "    with open('test_target.pickle', 'rb') as data:\n",
    "         test_target = pickle.load(data)\n",
    "    return torch.tensor(train_input,dtype=torch.float32), torch.tensor(validate_input,dtype=torch.float32), torch.tensor(test_input,dtype=torch.float32), torch.tensor(train_target,dtype=torch.float32), torch.tensor(validate_target,dtype=torch.float32), torch.tensor(test_target,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  torch.Size([5099, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "train_input,validate_input,test_input,train_target,validate_target,test_target=load_data()\n",
    "print(\"Train shape: \" ,train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, x, y):\n",
    "        'Initialization'\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.x)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = self.x[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= Dataset(train_input, train_target)\n",
    "test_dataset= Dataset(test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNetwork, self).__init__()\n",
    "        self.output_shape = (8,2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.unflatten = nn.Unflatten(1,self.output_shape)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(8*2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 8*2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        # print(x[0])\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        out = self.unflatten(logits)\n",
    "        # print(out[0])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (unflatten): Unflatten(dim=1, unflattened_size=(8, 2))\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=16, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LinearNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input. requires_grad = True\n",
    "train_input. requires_grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6634,  0.5903],\n",
      "        [ 0.4768, -0.8592],\n",
      "        [ 0.0575, -0.2041],\n",
      "        [ 0.4909, -1.4022],\n",
      "        [-0.4778,  1.3517],\n",
      "        [ 0.2441, -0.9381],\n",
      "        [-1.7007,  0.1728],\n",
      "        [-0.5561, -0.0388]], grad_fn=<SelectBackward0>)\n",
      "///////////\n",
      "tensor([-1.6634,  0.5903,  0.4768, -0.8592,  0.0575, -0.2041,  0.4909, -1.4022,\n",
      "        -0.4778,  1.3517,  0.2441, -0.9381, -1.7007,  0.1728, -0.5561, -0.0388],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([14.9352,  5.3071, 14.4947,  5.3293, 14.0542,  5.3515, 13.6137,  5.3737,\n",
      "        13.1726,  5.3937, 12.7264,  5.3937, 12.2802,  5.3937, 11.8340,  5.3937],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(train_input)\n",
    "y_pred.shape\n",
    "print (y_pred[0])\n",
    "sq = torch.flatten(y_pred,1)\n",
    "sq2 = torch.flatten(train_input,1)\n",
    "print(\"///////////\")\n",
    "print(sq[0])\n",
    "print(sq2[0])\n",
    "# temp = nn.Flatten(train_input)\n",
    "# train_input.shape,temp.shape,y_pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(47.2369)\n",
      "300 tensor(0.6566)\n",
      "600 tensor(0.7877)\n",
      "900 tensor(0.6171)\n",
      "1200 tensor(0.9639)\n",
      "1500 tensor(0.7391)\n",
      "1800 tensor(2.4894)\n",
      "2100 tensor(0.8386)\n",
      "2400 tensor(1.0475)\n",
      "2700 tensor(0.4876)\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    for epoch in range(3000):\n",
    "        y_pred = model(train_input) # make a prediction\n",
    "        loss = loss_fn(y_pred,train_target) # compute the loss\n",
    "        optimizer.zero_grad() # prepare the optimizer\n",
    "        loss.backward() # compute the contribution of each parameter to the loss\n",
    "        optimizer.step() # modify the parameters\n",
    "\n",
    "        if epoch % 300 == 0:\n",
    "            print(epoch, loss.data)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_error_double(prediction_train,prediction_test,train_target,test_target):\n",
    "                # # Show error rate\n",
    "        print(\"AVERAGE DISTANCE BETWEEN FIRST AND LAST POINT Train: \",prediction_displacement_double(train_target))\n",
    "        print(\"AVERAGE DISTANCE BETWEEN FIRST AND LAST POINT Test: \",prediction_displacement_double(test_target))\n",
    "             \n",
    "        #average_displacement_error\n",
    "        print(\"ADE ERROR RATE TEST: \", ADE_double_coordinates(prediction_test,test_target))\n",
    "        #average_displacement_error\n",
    "        print(\"ADE ERROR RATE TRAIN: \", ADE_double_coordinates(prediction_train,train_target))\n",
    "        print(\"//////////////////////////////////////////\")\n",
    "        #Final_displacement_error\n",
    "        print(\"FDE ERROR RATE TEST: \", FDE_double_coordinates(prediction_test,test_target))\n",
    "        print(\"FDE ERROR RATE TRAIN: \", FDE_double_coordinates(prediction_train,train_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowRegressionLSTM(nn.Module):\n",
    "    def __init__(self, num_features, hidden_units,out_features=16,isseq=True):\n",
    "        super().__init__()\n",
    "        self.seq = isseq\n",
    "        self.num_features = num_features  # this is the number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 1\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_features,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        # print(\"batch_size\",batch_size)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        \n",
    "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "        if(self.seq):\n",
    "            out = self.linear(hn[0]).reshape(batch_size,8,2) # First dim of Hn is num_layers, which is set to 1 above.\n",
    "        else:\n",
    "            out = self.linear(hn[0])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "num_hidden_units = 16\n",
    "hidden_size = 12\n",
    "n_features = 2\n",
    "num_layers = 1\n",
    "batch_size = 5\n",
    "\n",
    "LSTM_model = ShallowRegressionLSTM(num_features=n_features, hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(LSTM_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer,epochs=10):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for i in range (epochs):\n",
    "        total_loss = 0\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            # print(output.shape)\n",
    "            # print(y.shape)\n",
    "            loss = loss_function(output, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / num_batches\n",
    "        if (i+1)%5 == 0:\n",
    "            print(f\"Epoch {i+1} train loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train loss: 12.246922252341813\n",
      "Epoch 10 train loss: 5.72934009675667\n",
      "Epoch 15 train loss: 4.608505003731333\n",
      "Epoch 20 train loss: 3.767580728076727\n",
      "Epoch 25 train loss: 3.0283553304497666\n",
      "Epoch 30 train loss: 2.4091508976932543\n",
      "Epoch 35 train loss: 1.8859620055530733\n",
      "Epoch 40 train loss: 1.4727450577405226\n",
      "Epoch 45 train loss: 1.1456869817023878\n",
      "Epoch 50 train loss: 0.8708728728605909\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader, LSTM_model, loss_function, optimizer,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3789)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_pred = LSTM_model(test_input)\n",
    "    train_pred = LSTM_model(train_input)\n",
    "    loss = loss_fn(test_target, test_pred)\n",
    "    print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE DISTANCE BETWEEN FIRST AND LAST POINT Train:  1.7491152588806866\n",
      "AVERAGE DISTANCE BETWEEN FIRST AND LAST POINT Test:  2.7941778349259665\n",
      "ADE ERROR RATE TEST:  1.333707828970117\n",
      "ADE ERROR RATE TRAIN:  0.9344492040147702\n",
      "//////////////////////////////////////////\n",
      "FDE ERROR RATE TEST:  2.2891640075773427\n",
      "FDE ERROR RATE TRAIN:  1.599989753412669\n"
     ]
    }
   ],
   "source": [
    "show_error_double(train_pred,test_pred,train_target,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting only one point in the future\n",
    "train_target_one = train_target[:,0,:]\n",
    "test_target_one = test_target[:,0,:]\n",
    "train_dataset_one= Dataset(train_input, train_target_one)\n",
    "test_dataset_one= Dataset(test_input, test_target_one)\n",
    "train_loader_one = torch.utils.data.DataLoader(train_dataset_one, batch_size)\n",
    "test_loader_one = torch.utils.data.DataLoader(test_dataset_one, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "num_hidden_units = 16\n",
    "hidden_size = 12\n",
    "n_features = 2\n",
    "num_layers = 1\n",
    "batch_size = 5\n",
    "\n",
    "LSTM_model2 = ShallowRegressionLSTM(num_features=n_features, hidden_units=num_hidden_units,out_features=2,isseq=False)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(LSTM_model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train loss: 7.6770257825506665\n",
      "Epoch 10 train loss: 3.028978386417479\n",
      "Epoch 15 train loss: 1.7102254427592247\n",
      "Epoch 20 train loss: 1.043713672121949\n",
      "Epoch 25 train loss: 0.6145822825751869\n",
      "Epoch 30 train loss: 0.3691840190514317\n",
      "Epoch 35 train loss: 0.233049951416886\n",
      "Epoch 40 train loss: 0.15658085884426298\n",
      "Epoch 45 train loss: 0.11153401528309212\n",
      "Epoch 50 train loss: 0.08315793621456988\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader_one, LSTM_model2, loss_function, optimizer,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: 0.08635770529508591 \n",
      "loss_test: 0.1889965832233429\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_pred_one= LSTM_model2(test_input)\n",
    "    train_pred_one = LSTM_model2(train_input)\n",
    "    loss_train = loss_fn(train_target_one, train_pred_one)\n",
    "    loss_test = loss_fn(test_target_one, test_pred_one)\n",
    "    print(f'loss_train: {loss_train.data} \\nloss_test: {loss_test.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADE(pred,truth): \n",
    "    counter=0\n",
    "    sum=0\n",
    "    pred = pd.DataFrame(pred.cpu().numpy())\n",
    "    truth = pd.DataFrame(truth.cpu().numpy())\n",
    "    print(pred.shape)\n",
    "    for i in range(len(pred)):\n",
    "        half=int(len(pred[i])/2)\n",
    "        for j in range (half):\n",
    "\n",
    "            a = np.array((pred[i][j] , pred[i][half+j]))\n",
    "            b = np.array((truth.iloc[i][j] , truth.iloc[i][half+j]))\n",
    "\n",
    "            dist = np.linalg.norm(a-b)\n",
    "            sum+=dist\n",
    "            counter+=1\n",
    "            #print(\"Distance between\",a,\" and \",b,\" is: \",dist)\n",
    "\n",
    "    return (sum/counter)\n",
    "def FDE(pred,truth): \n",
    "    counter=0\n",
    "    sum=0\n",
    "    pred = pred.cpu().numpy()\n",
    "    truth = truth.cpu().numpy()\n",
    "\n",
    "    for ai,bi in zip(pred,truth):\n",
    "        # print(ai,bi)\n",
    "        dist = np.linalg.norm(ai-bi)\n",
    "        sum+=dist\n",
    "        counter+=1\n",
    "    return (sum/counter)\n",
    "\n",
    "\n",
    "def show_error_single(prediction_train,prediction_test,train_target,test_target):\n",
    "                # # Show error rate\n",
    "        print(\"AVERAGE DISTANCE BETWEEN FIRST AND LAST POINT Train: \",prediction_displacement(train_target))\n",
    "        print(\"AVERAGE DISTANCE BETWEEN FIRST AND LAST POINT Test: \",prediction_displacement(test_target))\n",
    "        print(\"////////////////////////////////////////////////\")\n",
    "        #average_displacement_error\n",
    "        print(\"ADE ERROR RATE TEST: \", FDE(prediction_test,test_target))\n",
    "        #average_displacement_error\n",
    "        print(\"ADE ERROR RATE TRAIN: \", FDE(prediction_train,train_target))\n",
    "        print(\"//////////////////////////////////////////\")\n",
    "        #Final_displacement_error\n",
    "        print(\"FDE ERROR RATE TEST: \", FDE(prediction_test,test_target))\n",
    "        print(\"FDE ERROR RATE TRAIN: \", FDE(prediction_train,train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE DISTANCE BETWEEN FIRST AND LAST POINT Train:  0.0\n",
      "AVERAGE DISTANCE BETWEEN FIRST AND LAST POINT Test:  0.0\n",
      "////////////////////////////////////////////////\n",
      "ADE ERROR RATE TEST:  0.4339348352825256\n",
      "ADE ERROR RATE TRAIN:  0.31064707524822427\n",
      "//////////////////////////////////////////\n",
      "FDE ERROR RATE TEST:  0.4339348352825256\n",
      "FDE ERROR RATE TRAIN:  0.31064707524822427\n"
     ]
    }
   ],
   "source": [
    "show_error_single(train_pred_one,test_pred_one,train_target_one,test_target_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torched')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b72875b808b4821a66c056bbb38de6a4c1e75d06274b19513bafe416aafb864f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
